import importlib.util
import sys
import numpy as np
import pandas as pd
import pulp
import time
import openpyxl
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.colors import TwoSlopeNorm
def set_plot_style():
    """ç»Ÿä¸€çš„å‡ºç‰ˆçº§ç»˜å›¾é£æ ¼ï¼ˆä¸­æ–‡ç¯å¢ƒï¼Œè®ºæ–‡å‹å¥½ï¼‰"""
    plt.rcParams.update({
        'font.sans-serif': ['SimHei', 'Microsoft YaHei UI', 'Arial Unicode MS', 'DejaVu Sans'],
        'axes.unicode_minus': False,
        'figure.dpi': 120,
        'savefig.dpi': 300,
        'axes.titlesize': 13,
        'axes.labelsize': 11.5,
        'xtick.labelsize': 10,
        'ytick.labelsize': 10,
        'legend.fontsize': 10,
        'axes.spines.top': False,
        'axes.spines.right': False,
        'grid.alpha': 0.3,
        'grid.linestyle': '--',
        'axes.grid': True,
        'lines.linewidth': 2.0,
    })


def load_problem2_impl():
    spec = importlib.util.spec_from_file_location(
        "p2_impl", "ç¬¬äºŒé¢˜_æœ€ç»ˆä¸¥æ ¼ç‰ˆæœ¬.py"
    )
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return module.FinalStrictPaperImplementation


class Problem3CorrelatedSubstitutionSolver:
    """
    é—®é¢˜ä¸‰ï¼šè€ƒè™‘ç›¸å…³æ€§ä¸æ›¿ä»£/äº’è¡¥å…³ç³»çš„éšæœºè§„åˆ’æ±‚è§£å™¨ï¼ˆåŸºäºé—®é¢˜äºŒæ‰©å±•ï¼‰
    - åœ¨é—®é¢˜äºŒçš„SAA+å†…ç”ŸCVaRæ¡†æ¶ä¸Šï¼ŒåŠ å…¥ï¼š
      1) ç›¸å…³æƒ…æ™¯ç”Ÿæˆï¼ˆP-D-Cè”åˆæ³¢åŠ¨ï¼ŒGaussian Copulaï¼‰
      2) è¿­ä»£ä¿®æ­£å‚æ•°ï¼ˆ~P, ~D, ~C ä¾èµ–ä¾›ç»™Sä¸å…³ç³»çŸ©é˜µÎ´ï¼‰
      3) æ›¿ä»£/äº’è¡¥çš„é¢ç§¯é…æ¯”çº¦æŸ
    - é‡‡ç”¨â€œå›ºå®š~å‚æ•° -> çº¿æ€§MILP -> æ›´æ–°~å‚æ•°â€çš„å¤–å±‚è¿­ä»£ï¼Œç¡®ä¿å¯è§£æ€§
    """

    def __init__(self):
        Base = load_problem2_impl()
        self.base = Base()

        # å…³ç³»ä¸ç›¸å…³æ€§å‚æ•°
        self.alpha_relation = 0.20  # å…³ç³»å¼ºåº¦ç³»æ•° Î±
        # ä¸‹è¿° Ï è§†ä¸ºâ€œç›®æ ‡ Spearman ç›¸å…³â€ï¼Œç”¨äº Copula æ ‡å®š
        self.rho_PD = -0.40         # ä»·æ ¼-é”€é‡ï¼ˆç›®æ ‡ Spearmanï¼Œè´Ÿï¼‰
        self.rho_DC = 0.15          # é”€é‡-æˆæœ¬ï¼ˆç›®æ ‡ Spearmanï¼Œæ­£ï¼‰
        self.rho_PC = 0.10          # ä»·æ ¼-æˆæœ¬ï¼ˆç›®æ ‡ Spearmanï¼Œå¼±æ­£ï¼‰

        self.sigma_p = 0.03         # ä»·æ ¼æ³¢åŠ¨å¼ºåº¦
        self.sigma_d = 0.05         # é”€é‡æ³¢åŠ¨å¼ºåº¦
        self.sigma_c = 0.02         # æˆæœ¬æ³¢åŠ¨å¼ºåº¦

        self.synergy_gain = 0.05    # è±†ç±»åèŒ¬å¢äº§5%ï¼ˆç”¨äºéªŒè¯é˜¶æ®µï¼‰

        # å…³ç³»çŸ©é˜µ Î´ï¼ˆç¤ºä¾‹ï¼‰ä¸é›†åˆ
        self.delta = {}  # (j, j2) -> delta
        self.strong_substitutes = set()  # å¼ºæ›¿ä»£ä½œç‰©é›†åˆ
        self.complement_pairs = []       # äº’è¡¥å¯¹ (j, j')

        # Copula ç›¸å…³çŸ©é˜µï¼ˆlatent Gaussianï¼‰
        self.copula_R = None

    # ---------- å…³ç³»è®¾ç½® ----------
    def build_relationships(self):
        # ä»…å¯¹å¸¸è§å¯¹è®¾ç½®ç¤ºä¾‹ï¼ˆè‹¥ä½œç‰©ç¼–å·ç¼ºå¤±åˆ™è‡ªåŠ¨è·³è¿‡ï¼‰
        # è¥¿çº¢æŸ¿(21)â€“èŒ„å­(22)ï¼šå¼ºæ›¿ä»£ -0.5
        self.delta[(21, 22)] = -0.5
        self.delta[(22, 21)] = -0.5
        self.strong_substitutes.update([21, 22])

        # å°éº¦(6)â€“ç‰ç±³(7)ï¼šä¸­æ›¿ä»£ -0.3
        self.delta[(6, 7)] = -0.3
        self.delta[(7, 6)] = -0.3

        # è±†ç±»(1) ä¸ å°éº¦/ç‰ç±³ï¼šå¼±äº’è¡¥ +0.2
        self.delta[(1, 6)] = 0.2
        self.delta[(6, 1)] = 0.2
        self.delta[(1, 7)] = 0.2
        self.delta[(7, 1)] = 0.2
        self.complement_pairs.extend([(1, 6), (1, 7)])

    # ---------- æƒ…æ™¯ç”Ÿæˆä¸ç›¸å…³æ€§æ³¨å…¥ ----------
    def generate_correlated_scenarios(self):
        self.base.generate_stochastic_scenarios()  # åŸºç¡€ï¼ˆç‹¬ç«‹ï¼‰æƒ…æ™¯
        # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿Copulaæ³¨å…¥å¯å¤ç°
        np.random.seed(2025)

        # â€”â€” Copula æ ‡å®šï¼šå°†ç›®æ ‡ Spearman ÏS æ˜ å°„åˆ° latent Gaussian ÏG â€”â€”
        # å…¬å¼ï¼šÏS = 6/Ï€ Â· arcsin(ÏG/2)  â‡”  ÏG = 2Â·sin(Ï€Â·ÏS/6)
        def spearman_to_gaussian_rho(r_s: float) -> float:
            return float(2.0 * np.sin(np.pi * r_s / 6.0))

        r_pd_g = spearman_to_gaussian_rho(self.rho_PD)
        r_dc_g = spearman_to_gaussian_rho(self.rho_DC)
        r_pc_g = spearman_to_gaussian_rho(self.rho_PC)

        R = np.array([
            [1.0,   r_pd_g, r_pc_g],
            [r_pd_g, 1.0,   r_dc_g],
            [r_pc_g, r_dc_g, 1.0  ],
        ])

        # ä¿éšœæ­£å®šæ€§ï¼ˆå¦‚æœ‰éœ€è¦ï¼Œæ·»åŠ è½»å¾®æŠ¬å‡ï¼‰
        eigvals = np.linalg.eigvalsh(R)
        if eigvals.min() < 1e-6:
            eps = abs(eigvals.min()) + 1e-6
            R = R + np.eye(3) * eps
        self.copula_R = R

        crop_ids = list(self.base.crop_info.keys())
        # è®°å½•ç”¨äºç›¸å…³æ£€éªŒçš„ä¹˜æ³•å› å­
        sample_p, sample_d, sample_c = [], [], []
        for k, scenario in enumerate(self.base.scenarios):
            for crop_id in crop_ids:
                if crop_id not in scenario:
                    continue
                for year in self.base.years:
                    if year not in scenario[crop_id]:
                        continue
                    year_data = scenario[crop_id][year]
                    # 3ç»´ç›¸å…³æ ‡å‡†æ­£æ€
                    z = np.random.multivariate_normal(mean=[0, 0, 0], cov=self.copula_R)
                    # å•è°ƒæ˜ å°„ä¸ºä¹˜æ³•å› å­ï¼ˆlog-normal å½¢å¼ï¼‰ï¼Œä¿æŒç§©æ¬¡ â†’ Spearman ä¸å˜
                    fp = float(np.exp(self.sigma_p * z[0]))  # ä»·æ ¼å› å­
                    fd = float(np.exp(self.sigma_d * z[1]))  # é”€é‡å› å­
                    fc = float(np.exp(self.sigma_c * z[2]))  # æˆæœ¬å› å­

                    year_data['price'] *= fp
                    year_data['sales_limit'] *= fd
                    year_data['cost_factor'] *= fc

                    sample_p.append(fp)
                    sample_d.append(fd)
                    sample_c.append(fc)

        # â€”â€” Copula æ ‡å®šæŠ¥å‘Šï¼ˆæ ·æœ¬ Spearman ä¸ç›®æ ‡çš„è¯¯å·®ï¼‰â€”â€”
        def spearman_corr(a, b):
            ra = pd.Series(a).rank().to_numpy()
            rb = pd.Series(b).rank().to_numpy()
            return float(np.corrcoef(ra, rb)[0, 1])

        sp_pd = spearman_corr(sample_p, sample_d)
        sp_dc = spearman_corr(sample_d, sample_c)
        sp_pc = spearman_corr(sample_p, sample_c)
        report = pd.DataFrame([
            {
                'pair': 'P-D',
                'target_spearman': self.rho_PD,
                'fitted_spearman': sp_pd,
                'abs_error': abs(sp_pd - self.rho_PD),
            },
            {
                'pair': 'D-C',
                'target_spearman': self.rho_DC,
                'fitted_spearman': sp_dc,
                'abs_error': abs(sp_dc - self.rho_DC),
            },
            {
                'pair': 'P-C',
                'target_spearman': self.rho_PC,
                'fitted_spearman': sp_pc,
                'abs_error': abs(sp_pc - self.rho_PC),
            },
        ])
        report.to_csv('é—®é¢˜ä¸‰_Copulaæ ‡å®šæŠ¥å‘Š.csv', index=False, encoding='utf-8-sig')
        print('ğŸ”§ Copula æ ‡å®šï¼šå·²è¾“å‡º é—®é¢˜ä¸‰_Copulaæ ‡å®šæŠ¥å‘Š.csv')

    # ---------- å¤–å±‚è¿­ä»£ï¼šä¿®æ­£å‚æ•° ~P, ~D, ~C ----------
    def compute_supply_mean_by_crop_year(self, x_solution):
        """æ ¹æ®å½“å‰è§£xä¸åœºæ™¯å¹³å‡äº§é‡ï¼Œä¼°ç®—å„ä½œç‰©-å¹´ä»½çš„å¹³å‡ä¾›ç»™ S_mean[j, t]"""
        crop_ids = list(self.base.crop_info.keys())
        land_names = list({**self.base.grain_lands, **self.base.irrigation_lands, **self.base.greenhouse_lands}.keys())

        # é¢„è®¡ç®—å„ä½œç‰©åœ¨æ¯å¹´å¹³å‡äº§é‡å› å­ E[yield_factor]
        E_yield = {}
        for crop_id in crop_ids:
            E_yield[crop_id] = {}
            for year in self.base.years:
                vals = [sc[crop_id][year]['yield_factor'] for sc in self.base.scenarios]
                E_yield[crop_id][year] = float(np.mean(vals))

        S_mean = {(crop_id, year): 0.0 for crop_id in crop_ids for year in self.base.years}

        for land in x_solution:
            for year in x_solution[land]:
                for season in x_solution[land][year]:
                    for crop_id, area in x_solution[land][year][season].items():
                        if area <= 0:
                            continue
                        y_base = self.base.crop_info[crop_id]['yield_base']
                        S_mean[(crop_id, year)] += area * y_base * E_yield[crop_id][year]

        return S_mean

    def compute_mean_D_by_crop_year(self):
        crop_ids = list(self.base.crop_info.keys())
        D_mean = {(crop_id, year): 0.0 for crop_id in crop_ids for year in self.base.years}
        for crop_id in crop_ids:
            for year in self.base.years:
                vals = [sc[crop_id][year]['sales_limit'] for sc in self.base.scenarios]
                D_mean[(crop_id, year)] = float(np.mean(vals))
        return D_mean

    def apply_tilde_updates(self, S_mean, D_mean):
        """æŒ‰ Î´ ä¸ S/D æ›´æ–° ~P, ~D, ~C çš„ç¼©æ”¾å› å­ï¼Œå¹¶å†™å›åœºæ™¯å­—å…¸"""
        crop_ids = list(self.base.crop_info.keys())

        price_scale = {}
        demand_scale = {}
        cost_scale = {}

        # å…ˆæŒ‰ä½œç‰©-å¹´è®¡ç®—ç¼©æ”¾ç³»æ•°ï¼ˆå¯¹æ‰€æœ‰æƒ…æ™¯ä¸€è‡´ï¼‰ï¼Œé¿å…åœ¨MILPä¸­å¼•å…¥è·¨æƒ…æ™¯è€¦åˆ
        for j in crop_ids:
            for t in self.base.years:
                # å…³ç³»å¯¹ä»·æ ¼çš„å½±å“ï¼š1 + Î± Â· Î£ Î´_{j,j'} Â· (S_{j'}/D_{j'})
                relation_term = 0.0
                for j2 in crop_ids:
                    if (j, j2) in self.delta:
                        ratio = 0.0
                        if D_mean.get((j2, t), 0.0) > 1e-9:
                            ratio = S_mean.get((j2, t), 0.0) / D_mean[(j2, t)]
                        relation_term += self.delta[(j, j2)] * ratio
                ps = 1.0 + self.alpha_relation * relation_term
                ps = float(np.clip(ps, 0.7, 1.3))

                # éœ€æ±‚å¯¹ä»·æ ¼å˜åŒ–çš„å¼¹æ€§ & äº’è¡¥å½±å“ï¼ˆæ­£Î´ï¼‰
                complement_term = 0.0
                for j2 in crop_ids:
                    if (j, j2) in self.delta and self.delta[(j, j2)] > 0:
                        if D_mean.get((j2, t), 0.0) > 1e-9:
                            complement_term += S_mean.get((j2, t), 0.0) / D_mean[(j2, t)]
                ds = 1.0 + self.rho_PD * (ps - 1.0) + 0.2 * complement_term
                ds = float(np.clip(ds, 0.7, 1.3))

                # æˆæœ¬éšé”€é‡èµ°é«˜
                base_ratio = 0.0
                if D_mean.get((j, t), 0.0) > 1e-9:
                    base_ratio = S_mean.get((j, t), 0.0) / D_mean[(j, t)]
                cs = 1.0 + self.rho_DC * base_ratio
                cs = float(np.clip(cs, 0.8, 1.2))

                price_scale[(j, t)] = ps
                demand_scale[(j, t)] = ds
                cost_scale[(j, t)] = cs

        # é˜»å°¼æ›´æ–°ï¼šÎ¸ â† (1âˆ’Î²)Â·Î¸ + Î²Â·Î¸_new ï¼ˆé¿å…å¤–å±‚éœ‡è¡ï¼‰
        beta = 0.5
        for sc in self.base.scenarios:
            for j in crop_ids:
                if j not in sc:
                    continue
                for t in self.base.years:
                    if t not in sc[j]:
                        continue
                    sc[j][t]['price'] = (1.0 - beta) * sc[j][t]['price'] + beta * (sc[j][t]['price'] * price_scale[(j, t)])
                    sc[j][t]['sales_limit'] = (1.0 - beta) * sc[j][t]['sales_limit'] + beta * (sc[j][t]['sales_limit'] * demand_scale[(j, t)])
                    sc[j][t]['cost_factor'] = (1.0 - beta) * sc[j][t]['cost_factor'] + beta * (sc[j][t]['cost_factor'] * cost_scale[(j, t)])

    # ---------- Ï/Î´ çµæ•åº¦ï¼ˆÂ±20%ï¼‰å¹¶è®°å½•ç¨³å¥æ€§ ----------
    def run_delta_rho_sensitivity(self, delta_scales=(0.8, 1.0, 1.2), rho_scales=(0.8, 1.0, 1.2), saa=20):
        print('\nğŸ§ª å¼€å§‹ Î´/Ï Â±20% çµæ•åº¦å®éªŒ...')
        results = []

        # å¤‡ä»½åŸå§‹å‚æ•°
        base_delta = dict(self.delta)
        base_rhos = (self.rho_PD, self.rho_DC, self.rho_PC)
        base_alpha = self.alpha_relation

        for ds in delta_scales:
            for rs in rho_scales:
                print(f"\nâ€”â€” ç»„åˆï¼šÎ´Ã—{ds:.2f}, ÏÃ—{rs:.2f}, SAA={saa} â€”â€”")

                # é‡ç½®æ•°æ®ä¸æƒ…æ™¯
                self.base.load_and_process_data()
                self.build_relationships()
                # æŒ‰æ¯”ä¾‹è°ƒæ•´ Î´ ä¸ Ïï¼ˆÎ´æ”¾å¤§é€šè¿‡ Î± ç»Ÿä¸€ç¼©æ”¾æ›´ç¨³å¦¥ï¼‰
                self.alpha_relation = base_alpha * ds
                self.rho_PD, self.rho_DC, self.rho_PC = [r * rs for r in base_rhos]

                # é‡æ–°ç”Ÿæˆä¸ç›¸å…³æ³¨å…¥
                self.base.generate_stochastic_scenarios()
                self.generate_correlated_scenarios()

                # SAAæ±‚è§£ï¼ˆå•è½®ï¼‰
                self.base.N_saa = saa
                self.base.select_representative_scenarios()
                self.base.build_stochastic_programming_model()
                ok = self.base.solve_model()
                if not ok:
                    print('   âš ï¸ æ±‚è§£å¤±è´¥ï¼Œè·³è¿‡è®°å½•')
                    continue
                metrics = self.validate_with_synergy()
                metrics.update({'delta_scale': ds, 'rho_scale': rs})
                results.append(metrics)

        if results:
            df = pd.DataFrame(results)
            df.to_csv('é—®é¢˜ä¸‰_Î´Ï_Â±20çµæ•åº¦.csv', index=False, encoding='utf-8-sig')
            print('âœ… å·²ç”Ÿæˆï¼šé—®é¢˜ä¸‰_Î´Ï_Â±20çµæ•åº¦.csv')
        # æ¢å¤
        self.delta = base_delta
        self.rho_PD, self.rho_DC, self.rho_PC = base_rhos
        self.alpha_relation = base_alpha

    def write_param_sources_note(self):
        text = (
            'ç›¸å…³æ€§/æ›¿ä»£æ€§å‚æ•°å£å¾„è¯´æ˜\n'
            'â€” ç›®æ ‡ Spearman ç›¸å…³ï¼ˆP-Dã€D-Cã€P-Cï¼‰å‚è€ƒå†œäº§å“éœ€æ±‚å¼¹æ€§ä¸æˆæœ¬ä¼ å¯¼çš„æ–‡çŒ®åŒºé—´ï¼š\n'
            '  â€¢ ä»·æ ¼-é”€é‡ï¼ˆP-Dï¼‰ï¼š-0.2 ~ -0.6ï¼ˆå†œäº§å“éœ€æ±‚ä»·æ ¼å¼¹æ€§å¼±åˆ°ä¸­ç­‰ï¼‰\n'
            '  â€¢ é”€é‡-æˆæœ¬ï¼ˆD-Cï¼‰ï¼š+0.10 ~ +0.30ï¼ˆéœ€æ±‚æ—ºç››æ—¶ç”¨å·¥/ç‰©æ–™æˆæœ¬ä¸Šè¡Œï¼‰\n'
            '  â€¢ ä»·æ ¼-æˆæœ¬ï¼ˆP-Cï¼‰ï¼š+0.05 ~ +0.20ï¼ˆä»·æ ¼ä¸Šè¡Œä¼´éšè¦ç´ ä»·æ ¼æŠ¬å‡ï¼‰\n'
            'â€” æœ¬æ¨¡å‹é‡‡ç”¨ä¸­ä½å€¼ä½œä¸ºåŸºçº¿ï¼Œå¹¶åœ¨ Â±20% åŒºé—´å†…åšçµæ•åº¦æ£€éªŒï¼›\n'
            'â€” Copula é‡‡ç”¨é«˜æ–¯Copulaï¼Œå¹¶å°†ç›®æ ‡ Spearman ÏS é€šè¿‡ ÏG=2Â·sin(Ï€Â·ÏS/6) æ˜ å°„åˆ° latent Gaussianï¼›\n'
            'â€” é‡‡æ ·ä½¿ç”¨å›ºå®šéšæœºç§å­ä»¥ç¡®ä¿å¯å¤ç°ï¼Œæ‹Ÿåˆè¯¯å·®è§â€œé—®é¢˜ä¸‰_Copulaæ ‡å®šæŠ¥å‘Š.csvâ€ã€‚\n'
        )
        with open('é—®é¢˜ä¸‰_ç›¸å…³æ€§å‚æ•°è¯´æ˜.txt', 'w', encoding='utf-8') as f:
            f.write(text)
        print('ğŸ“ å·²ç”Ÿæˆï¼šé—®é¢˜ä¸‰_ç›¸å…³æ€§å‚æ•°è¯´æ˜.txt')

    # ---------- äº’è¡¥/æ›¿ä»£ é¢ç§¯çº¦æŸï¼ˆåœ¨çˆ¶ç±»çº¦æŸåè¿½åŠ ï¼‰ ----------
    def add_relation_constraints(self):
        model = self.base.model
        all_lands = {**self.base.grain_lands, **self.base.irrigation_lands, **self.base.greenhouse_lands}
        land_names = list(all_lands.keys())
        crop_ids = list(self.base.crop_info.keys())

        # å¼ºæ›¿ä»£ï¼šè¯¥ç»„ä½œç‰©æ€»é¢ç§¯å æ¯” â‰¤ 40%ï¼ˆæŒ‰å¹´ï¼‰
        subs = [cid for cid in self.strong_substitutes if cid in crop_ids]
        if len(subs) >= 2:
            for year in self.base.years:
                sub_terms = []
                total_terms = []
                for land_name in land_names:
                    max_seasons = all_lands[land_name]['max_seasons']
                    for season in range(1, max_seasons + 1):
                        # subç»„
                        for j in subs:
                            if (land_name in self.base.x and j in self.base.x[land_name] and
                                year in self.base.x[land_name][j] and season in self.base.x[land_name][j][year]):
                                sub_terms.append(self.base.x[land_name][j][year][season])
                        # å…¨éƒ¨ä½œç‰©
                        for j in crop_ids:
                            if (land_name in self.base.x and j in self.base.x[land_name] and
                                year in self.base.x[land_name][j] and season in self.base.x[land_name][j][year]):
                                total_terms.append(self.base.x[land_name][j][year][season])

                if sub_terms and total_terms:
                    # Î£ x_sub - 0.4 * Î£ x_total â‰¤ 0
                    model += (pulp.lpSum(sub_terms) - 0.4 * pulp.lpSum(total_terms) <= 0,
                              f"strong_sub_share_year_{year}")

        # äº’è¡¥å¯¹ï¼šx_j â‰¥ (1/3) x_j' ï¼ˆæŒ‰å¹´ï¼‰
        for (j, j2) in self.complement_pairs:
            if j not in crop_ids or j2 not in crop_ids:
                continue
            for year in self.base.years:
                left_terms, right_terms = [], []
                for land_name in land_names:
                    max_seasons = all_lands[land_name]['max_seasons']
                    for season in range(1, max_seasons + 1):
                        if (land_name in self.base.x and j in self.base.x[land_name] and
                            year in self.base.x[land_name][j] and season in self.base.x[land_name][j][year]):
                            left_terms.append(self.base.x[land_name][j][year][season])
                        if (land_name in self.base.x and j2 in self.base.x[land_name] and
                            year in self.base.x[land_name][j2] and season in self.base.x[land_name][j2][year]):
                            right_terms.append(self.base.x[land_name][j2][year][season])
                if left_terms and right_terms:
                    model += (pulp.lpSum(left_terms) - (1.0/3.0) * pulp.lpSum(right_terms) >= 0,
                              f"complement_ratio_{j}_{j2}_{year}")

    # ---------- éªŒè¯ï¼ˆå¸¦è±†ç±»åèŒ¬å¢äº§ï¼‰ ----------
    def validate_with_synergy(self):
        print(f"\nğŸ¯ ä½¿ç”¨å…¨éƒ¨{self.base.N_scenarios}ä¸ªæƒ…æ™¯éªŒè¯ï¼ˆå«åèŒ¬å¢äº§ï¼‰...")
        scenario_profits = np.zeros(self.base.N_scenarios)
        sum_prod = 0.0
        sum_excess = 0.0

        for k, scenario in enumerate(self.base.scenarios):
            if k % 200 == 0:
                print(f"   éªŒè¯æƒ…æ™¯ {k+1}/{self.base.N_scenarios}...")

            total_profit = 0.0
            for land_name, land_solution in self.base.optimal_solution.items():
                for year, year_solution in land_solution.items():
                    # è®¡ç®—è¯¥åœ°å—å½“å¹´å­£èŠ‚1çš„è±†ç±»é¢ç§¯ï¼ˆç”¨äºåèŒ¬åˆ¤æ–­ï¼‰
                    bean_area_s1 = 0.0
                    if 1 in year_solution:
                        for crop_id, area in year_solution[1].items():
                            if self.base.crop_info[crop_id]['is_bean']:
                                bean_area_s1 += area

                    for season, season_solution in year_solution.items():
                        for crop_id, area in season_solution.items():
                            crop_info = self.base.crop_info[crop_id]
                            y = crop_info['yield_base'] * scenario[crop_id][year]['yield_factor']
                            c = crop_info['cost_base'] * scenario[crop_id][year]['cost_factor']
                            p = scenario[crop_id][year]['price']
                            d = scenario[crop_id][year]['sales_limit']

                            # åèŒ¬ï¼šè‹¥å­£èŠ‚1ç§è±†ç±»ï¼Œåˆ™å­£èŠ‚2éè±†ç±»å¢äº§5%
                            if season == 2 and bean_area_s1 > 0.01 and not crop_info['is_bean']:
                                y *= (1.0 + self.synergy_gain)

                            production = area * y
                            q_sell = min(production, d)
                            q_excess = max(0.0, production - d)
                            total_profit += q_sell * p + 0.5 * q_excess * p - area * c
                            sum_prod += production
                            sum_excess += q_excess

            scenario_profits[k] = total_profit

        expected_profit = float(np.mean(scenario_profits))
        profit_std = float(np.std(scenario_profits))
        var_5 = float(np.percentile(scenario_profits, 5))
        cvar_5 = float(np.mean(scenario_profits[scenario_profits <= var_5]))
        overprod_ratio = float(sum_excess / sum_prod) if sum_prod > 1e-9 else 0.0

        print("ğŸ“ˆ ç¨³å¥æ€§éªŒè¯ç»“æœ(å«åèŒ¬)ï¼š")
        print(f"   - æœŸæœ›æ”¶ç›Š: {expected_profit:,.2f} å…ƒ")
        print(f"   - æ ‡å‡†å·®: {profit_std:,.2f} å…ƒ ({profit_std/expected_profit*100:.1f}%)")
        print(f"   - 5% VaR: {var_5:,.2f} å…ƒ")
        print(f"   - 5% CVaR: {cvar_5:,.2f} å…ƒ")
        print(f"   - è¶…äº§æ¯”: {overprod_ratio*100:.2f}%")

        self.base.scenario_profits = scenario_profits
        return {
            'expected_profit': expected_profit,
            'profit_std': profit_std,
            'var_5': var_5,
            'cvar_5': cvar_5,
            'overproduction_ratio': overprod_ratio,
        }

    # ---------- å¯¼å‡ºä¸å¯è§†åŒ– ----------
    def save_results3(self, filename='é™„ä»¶3/result3.xlsx'):
        """å°†å½“å‰è§£æŒ‰é—®é¢˜ä¸‰å£å¾„å¯¼å‡ºåˆ°Excelï¼ˆæŒ‰ä½œç‰©-å¹´-å­£ã€åˆ†æ®µé”€å”®ä¼°è®¡æ”¶å…¥ï¼‰"""
        print(f"\nğŸ’¾ ä¿å­˜é—®é¢˜ä¸‰ç»“æœåˆ°: {filename}")
        result_data = []
        all_lands = {**self.base.grain_lands, **self.base.irrigation_lands, **self.base.greenhouse_lands}

        # é¢„è®¡ç®—å‡å€¼å‚æ•°ï¼ˆä»·æ ¼ã€é”€é‡ä¸Šé™ã€äº§é‡å› å­ï¼‰
        crop_ids = list(self.base.crop_info.keys())
        mean_price = {(j, t): float(np.mean([sc[j][t]['price'] for sc in self.base.scenarios])) for j in crop_ids for t in self.base.years}
        mean_D = {(j, t): float(np.mean([sc[j][t]['sales_limit'] for sc in self.base.scenarios])) for j in crop_ids for t in self.base.years}
        mean_yield_factor = {(j, t): float(np.mean([sc[j][t]['yield_factor'] for sc in self.base.scenarios])) for j in crop_ids for t in self.base.years}

        for land_name, land_solution in self.base.optimal_solution.items():
            land_type = all_lands[land_name]['type']
            for year, year_solution in land_solution.items():
                for season, season_solution in year_solution.items():
                    for crop_id, area in season_solution.items():
                        if area <= 0.01:
                            continue
                        crop_info = self.base.crop_info[crop_id]
                        y_base = crop_info['yield_base']
                        y = y_base * mean_yield_factor[(crop_id, year)]
                        p = mean_price[(crop_id, year)]
                        d = mean_D[(crop_id, year)]

                        production = area * y
                        q_sell = min(production, d)
                        q_excess = max(0.0, production - d)
                        revenue = q_sell * p + 0.5 * q_excess * p

                        result_data.append({
                            'åœ°å—åç§°': land_name,
                            'åœ°å—ç±»å‹': land_type,
                            'å¹´ä»½': year,
                            'å­£èŠ‚': season,
                            'ä½œç‰©ç¼–å·': crop_id,
                            'ä½œç‰©åç§°': crop_info['name'],
                            'ç§æ¤é¢ç§¯(äº©)': round(area, 2),
                            'é¢„æœŸäº§é‡(æ–¤)': round(production, 2),
                            'é¢„æœŸæ”¶å…¥(å…ƒ)': round(revenue, 2)
                        })

        workbook = openpyxl.Workbook()
        ws = workbook.active
        ws.title = "ç§æ¤æ–¹æ¡ˆ"
        headers = ['åœ°å—åç§°', 'åœ°å—ç±»å‹', 'å¹´ä»½', 'å­£èŠ‚', 'ä½œç‰©ç¼–å·', 'ä½œç‰©åç§°', 'ç§æ¤é¢ç§¯(äº©)', 'é¢„æœŸäº§é‡(æ–¤)', 'é¢„æœŸæ”¶å…¥(å…ƒ)']
        for col, header in enumerate(headers, 1):
            ws.cell(row=1, column=col, value=header)
        for row, data in enumerate(result_data, 2):
            for col, header in enumerate(headers, 1):
                ws.cell(row=row, column=col, value=data[header])
        workbook.save(filename)
        print(f"âœ… ç»“æœå·²ä¿å­˜ï¼Œå…± {len(result_data)} æ¡è®°å½•")

    def generate_relation_heatmap(self, filename='å›¾7.1_ä½œç‰©å…³ç³»çƒ­åŠ›å›¾.png'):
        """æ ¹æ®å·²è®¾å®šçš„Î´å¯¹ï¼Œç»˜åˆ¶ç´§å‡‘çš„å…³ç³»çƒ­åŠ›å›¾ï¼ˆä»…å«å‡ºç°è¿‡çš„ä½œç‰©ï¼‰"""
        print("\nğŸ“Š ç”Ÿæˆå…³ç³»çƒ­åŠ›å›¾...")
        set_plot_style()

        crops_used = sorted({j for (j, _) in self.delta.keys()} | {j2 for (_, j2) in self.delta.keys()})
        if not crops_used:
            print("âš ï¸ æœªå®šä¹‰å…³ç³»å¯¹ï¼Œè·³è¿‡ç»˜å›¾")
            return

        names = [self.base.crop_info[j]['name'] if j in self.base.crop_info else str(j) for j in crops_used]
        M = np.zeros((len(crops_used), len(crops_used)))
        for a, j in enumerate(crops_used):
            for b, j2 in enumerate(crops_used):
                M[a, b] = self.delta.get((j, j2), 0.0)

        fig, ax = plt.subplots(figsize=(7.2, 5.8))
        norm = TwoSlopeNorm(vmin=-0.6, vcenter=0.0, vmax=0.6)
        im = ax.imshow(M, cmap='RdBu_r', norm=norm)
        ax.set_xticks(range(len(crops_used)))
        ax.set_yticks(range(len(crops_used)))
        ax.set_xticklabels(names, rotation=45, ha='right')
        ax.set_yticklabels(names)
        ax.set_title('ä½œç‰©å…³ç³»çƒ­åŠ›å›¾ï¼ˆÎ´ï¼Œæ­£=äº’è¡¥ï¼Œè´Ÿ=æ›¿ä»£ï¼‰')
        for spine in ax.spines.values():
            spine.set_visible(True)
            spine.set_linewidth(0.8)
        for i in range(M.shape[0]):
            for j in range(M.shape[1]):
                val = M[i, j]
                if abs(val) > 1e-6:
                    ax.text(j, i, f"{val:.1f}", ha='center', va='center', fontsize=8.5, color='black')
        cbar = fig.colorbar(im, shrink=0.92)
        cbar.ax.set_ylabel('å…³ç³»å¼ºåº¦ Î´', rotation=90, labelpad=10)
        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ç”Ÿæˆï¼š{filename}")

    def generate_price_supply_scatter(self, filename='å›¾7.2_ä»·æ ¼-ä¾›ç»™æ•£ç‚¹.png'):
        print("\nğŸ“Š ç”Ÿæˆä»·æ ¼-ä¾›ç»™æ•£ç‚¹å›¾ï¼ˆä¼˜åŒ–ï¼‰...")
        set_plot_style()

        # å¹³å‡ä¾›ç»™ä¸ä»·æ ¼ï¼ˆæŒ‰ä½œç‰©-å¹´å¹³å‡ï¼‰ï¼Œä¾›ç»™ç”¨è§£çš„ S_mean
        S_mean = self.compute_supply_mean_by_crop_year(self.base.optimal_solution)
        crop_ids = list(self.base.crop_info.keys())
        P_mean = {(j, t): float(np.mean([sc[j][t]['price'] for sc in self.base.scenarios])) for j in crop_ids for t in self.base.years}

        xs, ys = [], []
        for j in crop_ids:
            for t in self.base.years:
                s = S_mean.get((j, t), 0.0)
                if s <= 0:
                    continue
                xs.append(s / 1e6)  # å•ä½ï¼šç™¾ä¸‡æ–¤
                ys.append(P_mean[(j, t)])

        if len(xs) == 0:
            print("âš ï¸ å½“å‰è§£ä¾›ç»™ä¸º0ï¼Œè·³è¿‡ç»˜å›¾")
            return

        xs = np.array(xs, dtype=float)
        ys = np.array(ys, dtype=float)

        # è®¡ç®— Pearson ä¸ Spearman
        r_pearson = float(np.corrcoef(xs, ys)[0, 1]) if len(xs) > 1 else np.nan
        rank_x = pd.Series(xs).rank().to_numpy()
        rank_y = pd.Series(ys).rank().to_numpy()
        r_spearman = float(np.corrcoef(rank_x, rank_y)[0, 1]) if len(xs) > 1 else np.nan

        # èƒœä»»çš„å¯è§†åŒ–ï¼šå·¦å³åŒå›¾ï¼ˆå·¦ï¼šå…¨å±€æ•£ç‚¹+ç¨³å¥æ‹Ÿåˆï¼›å³ï¼šå°ä¾›ç»™åŒºå¯†åº¦ï¼‰
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12.5, 5.6))

        # 1) å…¨å±€æ•£ç‚¹ + 95%åˆ†ä½ç¨³å¥æ‹Ÿåˆï¼ˆå»æç«¯ï¼‰
        qx_lo, qx_hi = np.quantile(xs, [0.025, 0.975])
        qy_lo, qy_hi = np.quantile(ys, [0.025, 0.975])
        mask = (xs >= qx_lo) & (xs <= qx_hi) & (ys >= qy_lo) & (ys <= qy_hi)
        xs_fit, ys_fit = xs[mask], ys[mask]
        if len(xs_fit) >= 2:
            coef = np.polyfit(xs_fit, ys_fit, 1)
            xline = np.linspace(xs.min(), xs.max(), 200)
            yline = np.polyval(coef, xline)
        else:
            coef = [np.nan, np.nan]
            xline = np.array([xs.min(), xs.max()])
            yline = np.array([ys.mean(), ys.mean()])

        ax1.scatter(xs, ys, c='tab:blue', alpha=0.65, s=30, linewidths=0, rasterized=True)
        ax1.plot(xline, yline, color='tab:red', linestyle='--', linewidth=2,
                 label=f"OLS(95%åŒºé—´): y={coef[0]:.2f}x+{coef[1]:.2f}")
        ax1.set_xlabel('ä¾›ç»™é‡ Sï¼ˆç™¾ä¸‡æ–¤ï¼‰')
        ax1.set_ylabel('å‡ä»·ï¼ˆå…ƒ/æ–¤ï¼‰')
        ax1.set_title(f'ä»·æ ¼â€”ä¾›ç»™å…³ç³»ï¼ˆæŒ‰ä½œç‰©-å¹´èšåˆï¼‰')
        ax1.legend(loc='upper right')
        ax1.grid(alpha=0.3)
        ax1.text(0.02, 0.02, f"Pearson r={r_pearson:.2f}\nSpearman Ï={r_spearman:.2f}",
                 transform=ax1.transAxes, fontsize=9,
                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.7, edgecolor='lightgray'))

        # 2) å°ä¾›ç»™åŒºå¯†åº¦ï¼ˆhexbinï¼‰ï¼Œçªå‡ºè¿‘åŸç‚¹æ‹¥æŒ¤åŒº
        x_zoom_max = float(np.quantile(xs, 0.85))  # è‡ªé€‚åº”æ”¾å¤§åˆ°85%åˆ†ä½
        ax2.hexbin(xs, ys, gridsize=28, cmap='viridis', extent=[0, x_zoom_max, ys.min(), ys.max()],
                   mincnt=1)
        ax2.set_xlim(0, x_zoom_max)
        ax2.set_xlabel('ä¾›ç»™é‡ Sï¼ˆç™¾ä¸‡æ–¤ï¼Œè¿‘åŸç‚¹æ”¾å¤§ï¼‰')
        ax2.set_ylabel('å‡ä»·ï¼ˆå…ƒ/æ–¤ï¼‰')
        ax2.set_title('è¿‘åŸç‚¹å¯†åº¦ï¼ˆHexbinï¼‰')
        cb = fig.colorbar(ax2.collections[0], ax=ax2)
        cb.set_label('è®¡æ•°')
        # æ¬¡è½´ä¸é¢å¤–ç½‘æ ¼ï¼Œä¿æŒä¸»å›¾é£æ ¼ç»Ÿä¸€

        fig.suptitle('å›¾7.2 ä»·æ ¼â€”ä¾›ç»™å…³ç³»ï¼šå…¨å±€æ‹Ÿåˆä¸å±€éƒ¨å¯†åº¦', fontsize=13)
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ç”Ÿæˆï¼š{filename}")

    def generate_q2_vs_q3_boxplot(self, filename='é—®é¢˜2_vs_é—®é¢˜3_æ”¶ç›Šç®±çº¿å›¾.png', csvfile='é—®é¢˜2_vs_é—®é¢˜3_å…³é”®æŒ‡æ ‡.csv'):
        print("\nğŸ“Š ç”Ÿæˆé—®é¢˜2 vs é—®é¢˜3 æ”¶ç›Šå¯¹æ¯”ç®±çº¿å›¾...")
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
        plt.rcParams['axes.unicode_minus'] = False

        # è¿è¡Œé—®é¢˜2ï¼ˆç›¸åŒK=1000ï¼ŒSAA=å½“å‰å€¼ï¼‰ï¼Œè·å–åœºæ™¯æ”¶ç›Š
        Base = load_problem2_impl()
        q2 = Base()
        q2.N_saa = self.base.N_saa
        q2.load_and_process_data()
        q2.generate_stochastic_scenarios()
        q2.select_representative_scenarios()
        # å°¾éƒ¨å¢çº¦ç¨³å¥æ€§ï¼šå¯¹ä¸åŒMè¿›è¡ŒéªŒè¯ï¼ˆå¯é€‰ï¼‰
        q2.use_tail_cvar = True
        for M in [int(0.1*q2.N_saa), int(0.2*q2.N_saa), q2.N_saa]:
            q2.tail_M = max(1, M)
            # åˆæ­¥ä½¿ç”¨æ‰€æœ‰ä»£è¡¨æ€§æƒ…æ™¯çš„æœ€å·®é›†åˆï¼šå…ˆä»¥ç‹¬ç«‹æŸå¤±æ’åºç¡®å®š
            q2.tail_active_indices = None  # è®©æ¨¡å‹å†…é‡‡ç”¨é»˜è®¤åˆå€¼
        q2.build_stochastic_programming_model()
        ok = q2.solve_model()
        if not ok:
            print("âš ï¸ é—®é¢˜2æ±‚è§£å¤±è´¥ï¼Œè·³è¿‡å¯¹æ¯”")
            return
        q2_profits = np.array(q2.scenario_profits, dtype=float)

        # é—®é¢˜3æ”¶ç›Šï¼ˆå·²å«åèŒ¬éªŒè¯ï¼‰
        q3_profits = np.array(self.base.scenario_profits, dtype=float)

        # æŒ‡æ ‡
        def metrics(arr):
            mu = float(np.mean(arr))
            std = float(np.std(arr))
            var5 = float(np.percentile(arr, 5))
            cvar5 = float(np.mean(arr[arr <= var5]))
            return mu, std, var5, cvar5
        m2 = metrics(q2_profits)
        m3 = metrics(q3_profits)

        pd.DataFrame([
            {'æ–¹æ¡ˆ': 'é—®é¢˜2', 'æœŸæœ›æ”¶ç›Š': m2[0], 'æ ‡å‡†å·®': m2[1], 'VaR5%': m2[2], 'CVaR5%': m2[3]},
            {'æ–¹æ¡ˆ': 'é—®é¢˜3', 'æœŸæœ›æ”¶ç›Š': m3[0], 'æ ‡å‡†å·®': m3[1], 'VaR5%': m3[2], 'CVaR5%': m3[3]},
        ]).to_csv(csvfile, index=False, encoding='utf-8-sig')

        fig, ax = plt.subplots(figsize=(7.5, 5.5))
        data_million = [q2_profits / 1e6, q3_profits / 1e6]
        ax.boxplot(data_million, labels=['é—®é¢˜äºŒ', 'é—®é¢˜ä¸‰'], patch_artist=True,
                   boxprops=dict(facecolor='lightsteelblue'), medianprops=dict(color='red'))
        ax.set_ylabel('æ”¶ç›Šï¼ˆç™¾ä¸‡å…ƒï¼‰')
        ax.set_title('é—®é¢˜äºŒ vs é—®é¢˜ä¸‰ æ”¶ç›Šåˆ†å¸ƒå¯¹æ¯”ï¼ˆ1000æƒ…æ™¯ï¼‰')
        # æ ‡æ³¨å‡å€¼
        means = [np.mean(d) for d in data_million]
        for i, m in enumerate(means, start=1):
            ax.text(i, m, f"å‡å€¼={m:.1f}", ha='center', va='bottom', fontsize=9, color='dimgray')
        ax.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ç”Ÿæˆï¼š{filename} ä¸ {csvfile}")

    # ---------- ä¸»æµç¨‹ ----------
    def run(self, iterations=2, tail_M: int | None = None, test_tail_robustness: bool = False):
        print("\nğŸš€ é—®é¢˜ä¸‰ï¼šç›¸å…³æ€§ä¸æ›¿ä»£æ€§ æ‰©å±•æ±‚è§£ å¼€å§‹")
        t0 = time.time()

        # 1) æ•°æ®åŠ è½½ä¸åŸºç¡€æƒ…æ™¯
        self.base.load_and_process_data()
        self.build_relationships()
        self.base.generate_stochastic_scenarios()  # åŸºç¡€
        self.generate_correlated_scenarios()       # æ³¨å…¥ç›¸å…³

        # 2) å¤–å±‚è¿­ä»£ï¼š~P,~D,~C ä¿®æ­£ + MILP æ±‚è§£
        # åˆå§‹ï¼šä¸ä¿®æ­£ï¼ˆä½¿ç”¨ç›¸å…³åçš„åŸºç¡€æƒ…æ™¯ï¼‰
        x_sol_last = None
        # æ”¶æ•›åˆ¤æ®ï¼šè§£çš„å‡æ–¹å˜åŒ–ç‡ < 1e-3ï¼Œæœ€å¤š10æ¬¡
        max_iters = min(10, iterations)
        tol = 1e-3
        prev_vector = None
        for it in range(1, max_iters + 1):
            print(f"\n==== å¤–å±‚è¿­ä»£ {it}/{iterations} ====")

            # SAA é€‰æƒ…æ™¯ + æ„å»ºä¸æ±‚è§£
            self.base.select_representative_scenarios()
            # å°¾éƒ¨å¢çº¦ï¼ˆå¯é€‰ï¼‰ï¼šå¯ç”¨å¹¶è¿›è¡Œ2è½®ä¸»åŠ¨é›†æ›´æ–°
            if tail_M is not None and tail_M > 0:
                self.solve_with_tail_cvar(tail_M, max_rounds=2)
                ok = (self.base.optimal_solution is not None)
            else:
                self.base.use_tail_cvar = False
                self.base.tail_M = None
                self.base.tail_active_indices = None
                self.base.build_stochastic_programming_model()
                ok = self.base.solve_model()
            if not ok:
                print("âš ï¸ MILP æ±‚è§£å¤±è´¥ï¼Œæå‰ç»“æŸè¿­ä»£")
                break

            # ä¼°ç®—ä¾›ç»™ä¸æ›´æ–° ~å‚æ•°
            S_mean = self.compute_supply_mean_by_crop_year(self.base.optimal_solution)
            D_mean = self.compute_mean_D_by_crop_year()
            self.apply_tilde_updates(S_mean, D_mean)
            x_sol_last = self.base.optimal_solution

            # æ”¶æ•›æ£€æµ‹ï¼šå°†xå±•å¼€ä¸ºå‘é‡
            vec = []
            for land_name in sorted(self.base.optimal_solution.keys()):
                for year in sorted(self.base.optimal_solution[land_name].keys()):
                    for season in sorted(self.base.optimal_solution[land_name][year].keys()):
                        for crop_id in sorted(self.base.optimal_solution[land_name][year][season].keys()):
                            vec.append(self.base.optimal_solution[land_name][year][season][crop_id])
            vec = np.array(vec, dtype=float) if vec else np.zeros(1)
            if prev_vector is not None and prev_vector.size == vec.size:
                denom = max(1e-8, np.linalg.norm(prev_vector))
                rel_change = float(np.linalg.norm(vec - prev_vector) / denom)
                print(f"   â†³ å¤–å±‚ç›¸å¯¹å˜åŒ–ç‡: {rel_change:.3e}")
                if rel_change < tol:
                    print("   âœ… æ»¡è¶³æ”¶æ•›åˆ¤æ®ï¼Œæå‰åœæ­¢å¤–å±‚è¿­ä»£")
                    break
            prev_vector = vec

        # 3) éªŒè¯ï¼ˆå«åèŒ¬å¢äº§ï¼‰ï¼Œè¾“å‡ºæŒ‡æ ‡
        metrics = self.validate_with_synergy()
        # å¯é€‰ï¼šå¯¹ä¸åŒMåšç¨³å¥æ€§æ£€éªŒ
        if test_tail_robustness:
            try:
                self.run_tail_M_robustness()
            except Exception as e:
                print(f"âš ï¸ å°¾éƒ¨å¢çº¦ç¨³å¥æ€§æµ‹è¯•å‡ºé”™ï¼š{e}")
        # å¯¼å‡ºExcelä¸å›¾
        try:
            self.save_results3()
            self.generate_relation_heatmap()
            self.generate_price_supply_scatter()
            self.generate_q2_vs_q3_boxplot()
            # æ–°å¢ï¼šå€’éœ€æ±‚æ›²çº¿ï¼ˆÎ´å¯¹æ¯”ï¼‰ã€ä½œä¸šæ¸…å•ä¸ç”˜ç‰¹å›¾ã€å¤§æ£šæœˆåº¦åˆ©ç”¨ç‡
            self.generate_inverse_demand_shift_plot()
            self.export_operation_schedule_and_gantt()
            self.generate_greenhouse_monthly_utilization()
        except Exception as e:
            print(f"âš ï¸ åå¤„ç†å‡ºé”™ï¼š{e}")
        total_time = time.time() - t0
        print(f"\nğŸ é—®é¢˜ä¸‰æ±‚è§£å®Œæˆï¼Œç”¨æ—¶ {total_time:.2f} ç§’")
        return metrics

    # ---------- æ¶ˆèå®éªŒï¼šBaseline / ä»…Copula / ä»…Î´ / ä¸¤è€…çš†æœ‰ ----------
    def run_ablation_experiments(self, out_csv='é—®é¢˜ä¸‰_æ¶ˆèå®éªŒ.csv', saa: int | None = None):
        """å››ç§é…ç½®æ¶ˆèï¼š
        - baseline: æ— ç›¸å…³ï¼ˆä¸æ³¨å…¥Copulaï¼Œä¸å¯ç”¨Î´æ›´æ–°ï¼‰
        - copula_only: ä»…æ³¨å…¥Copulaç›¸å…³
        - delta_only: ä»…å¯ç”¨Î´å…³ç³»ï¼ˆå«~å‚æ•°æ›´æ–°ä¸é˜»å°¼ï¼‰
        - both: Copula + Î´
        è¾“å‡ºæ¯ç§é…ç½®çš„ E[Profit], CVaR5%, è¶…äº§æ¯”ï¼Œå¹¶ç»™å‡ºç›¸å¯¹baselineçš„på€¼ï¼ˆWelchè¿‘ä¼¼ï¼‰ã€‚
        """
        import math

        def pvalue_welch(a: np.ndarray, b: np.ndarray) -> float:
            a = np.array(a, dtype=float).ravel()
            b = np.array(b, dtype=float).ravel()
            na, nb = len(a), len(b)
            if na == 0 or nb == 0:
                return float('nan')
            ma, mb = float(np.mean(a)), float(np.mean(b))
            va, vb = float(np.var(a, ddof=1)), float(np.var(b, ddof=1))
            se = math.sqrt(va/na + vb/nb) if (va>0 or vb>0) else 1e-12
            z = (mb - ma) / se
            # æ­£æ€è¿‘ä¼¼på€¼
            p = 2.0 * 0.5 * math.erfc(abs(z) / math.sqrt(2.0))
            return float(p)

        configs = [
            ('baseline', dict(copula=False, delta=False, tilde=False)),
            ('copula_only', dict(copula=True, delta=False, tilde=False)),
            ('delta_only', dict(copula=False, delta=True, tilde=True)),
            ('both', dict(copula=True, delta=True, tilde=True)),
        ]

        rows = []
        profits_map = {}

        for name, cfg in configs:
            # é‡ç½®å¹¶è¿è¡Œå•é…ç½®
            res, profits = self._solve_ablation_single(cfg, saa=saa)
            profits_map[name] = profits
            rows.append({
                'config': name,
                **res
            })

        # på€¼ç›¸å¯¹baselineï¼ˆæ”¶ç›Šå‡å€¼ï¼‰
        base = profits_map.get('baseline')
        if base is not None:
            for row in rows:
                name = row['config']
                if name == 'baseline':
                    row['p_value_vs_baseline'] = 1.0
                else:
                    row['p_value_vs_baseline'] = pvalue_welch(base, profits_map.get(name, []))

        df = pd.DataFrame(rows)
        df.to_csv(out_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… å·²ç”Ÿæˆï¼š{out_csv}")
        return df

    def _solve_ablation_single(self, cfg: dict, saa: int | None = None):
        # ç»Ÿä¸€æ•°æ®ä¸æƒ…æ™¯
        self.base.load_and_process_data()
        # å…³ç³»è®¾ç½®
        self.delta.clear(); self.complement_pairs.clear(); self.strong_substitutes.clear()
        self.alpha_relation = 0.0
        if cfg.get('delta', False):
            self.build_relationships()
            self.alpha_relation = 0.20
        # åŸºç¡€æƒ…æ™¯
        self.base.generate_stochastic_scenarios()
        # Copulaæ³¨å…¥
        if cfg.get('copula', False):
            self.generate_correlated_scenarios()
        # SAA
        if saa is not None:
            self.base.N_saa = saa
        self.base.select_representative_scenarios()

        # ç¦ç”¨å°¾éƒ¨å¢çº¦
        self.base.use_tail_cvar = False
        self.base.tail_M = None
        self.base.tail_active_indices = None

        # æ±‚è§£
        self.base.build_stochastic_programming_model()
        ok = self.base.solve_model()
        if not ok:
            return ({'expected_profit': float('nan'), 'cvar_5': float('nan'), 'overproduction_ratio': float('nan')}, np.array([]))

        # æ˜¯å¦è¿›è¡Œ~å‚æ•°é˜»å°¼æ›´æ–°ï¼ˆä¸€æ¬¡ï¼‰
        if cfg.get('tilde', False):
            S_mean = self.compute_supply_mean_by_crop_year(self.base.optimal_solution)
            D_mean = self.compute_mean_D_by_crop_year()
            self.apply_tilde_updates(S_mean, D_mean)
            # é‡æ–°æ±‚è§£ä¸€æ¬¡ï¼ˆä¿æŒå…¬å¹³ï¼Œä»ä¸å¯ç”¨å°¾éƒ¨å¢çº¦ï¼‰
            self.base.select_representative_scenarios()
            self.base.build_stochastic_programming_model()
            ok = self.base.solve_model()
            if not ok:
                pass

        metrics = self.validate_with_synergy()
        profits = np.array(self.base.scenario_profits, dtype=float)
        out = {
            'E_profit': metrics['expected_profit'],
            'CVaR5': metrics['cvar_5'],
            'OverProdRatio': metrics['overproduction_ratio'],
        }
        return out, profits

    # ---------- å°¾éƒ¨å¢çº¦ï¼šä¸»åŠ¨é›†æ›´æ–°æ±‚è§£ ----------
    def solve_with_tail_cvar(self, M: int, max_rounds: int = 2):
        """å¯ç”¨å°¾éƒ¨å¢çº¦ï¼šä»…å¯¹SAAä»£è¡¨æ€§æƒ…æ™¯ä¸­æœ€å·®çš„Mä¸ªæ–½åŠ CVaRçº¦æŸï¼Œå¹¶è¿›è¡Œä¸»åŠ¨é›†(Active Set)æ›´æ–°ã€‚"""
        self.base.use_tail_cvar = True
        self.base.tail_M = int(max(1, M))
        self.base.tail_active_indices = None  # ç¬¬ä¸€æ¬¡ç”¨é»˜è®¤åˆå€¼
        # ç¬¬ä¸€æ¬¡æ„å»ºå¹¶æ±‚è§£
        self.base.build_stochastic_programming_model()
        ok = self.base.solve_model()
        if not ok:
            return False
        # ä¸»åŠ¨é›†æ›´æ–°
        for r in range(1, max_rounds):
            worst = self._select_worst_selected_indices(self.base.optimal_solution)
            if worst == self.base.tail_active_indices:
                break
            self.base.tail_active_indices = worst
            self.base.build_stochastic_programming_model()
            ok = self.base.solve_model()
            if not ok:
                break
        return ok

    def _select_worst_selected_indices(self, x_solution):
        """åŸºäºå½“å‰è§£ï¼Œè®¡ç®—SAAä»£è¡¨æ€§æƒ…æ™¯çš„æŸå¤±ï¼Œè¿”å›æœ€å·®Mä¸ªçš„ç´¢å¼•åˆ—è¡¨ã€‚"""
        n = len(self.base.selected_scenarios)
        M = int(max(1, min(self.base.tail_M or n, n)))
        losses = []
        for k, scenario in enumerate(self.base.selected_scenarios):
            profit = 0.0
            for land_name, land_solution in x_solution.items():
                for year, year_solution in land_solution.items():
                    for season, season_solution in year_solution.items():
                        for crop_id, area in season_solution.items():
                            crop_info = self.base.crop_info[crop_id]
                            y = crop_info['yield_base'] * scenario[crop_id][year]['yield_factor']
                            c = crop_info['cost_base'] * scenario[crop_id][year]['cost_factor']
                            p = scenario[crop_id][year]['price']
                            d = scenario[crop_id][year]['sales_limit']
                            production = area * y
                            q_sell = min(production, d)
                            q_excess = max(0.0, production - d)
                            profit += q_sell * p + 0.5 * q_excess * p - area * c
            losses.append((-profit, k))  # æŸå¤±= -åˆ©æ¶¦
        losses.sort(reverse=True)  # ä»å¤§åˆ°å°ï¼ˆæ›´å·®åœ¨å‰ï¼‰
        worst_indices = [k for _, k in losses[:M]]
        return worst_indices

    def run_tail_M_robustness(self, Ms: list[int] | None = None, out_csv='é—®é¢˜ä¸‰_å°¾éƒ¨å¢çº¦_Mç¨³å¥æ€§.csv'):
        """å¯¹ä¸åŒMï¼ˆå°¾éƒ¨æƒ…æ™¯æ•°é‡ï¼‰è¿›è¡Œæ±‚è§£ä¸å…¨æƒ…æ™¯éªŒè¯ï¼Œè¾“å‡ºç¨³å¥æ€§ç»“æœã€‚"""
        if Ms is None:
            Ms = [max(1, int(0.1 * self.base.N_saa)), max(1, int(0.2 * self.base.N_saa)), self.base.N_saa]
        rows = []
        for M in Ms:
            # é‡æ–°é€‰æ‹©ä»£è¡¨æ€§æƒ…æ™¯ï¼ˆä¿è¯å¯é‡å¤æ€§ï¼‰
            self.base.select_representative_scenarios()
            t0 = time.time()
            ok = self.solve_with_tail_cvar(M, max_rounds=2)
            t1 = time.time()
            if not ok:
                continue
            metrics = self.validate_with_synergy()
            rows.append({
                'M': M,
                'solve_time_sec': round(t1 - t0, 2),
                **metrics
            })
        if rows:
            pd.DataFrame(rows).to_csv(out_csv, index=False, encoding='utf-8-sig')
            print(f"âœ… å·²ç”Ÿæˆï¼š{out_csv}")

    # ---------- å€’éœ€æ±‚æ›²çº¿ï¼šä¸»ç²®/ä¸»èœï¼ŒÎ´å¯¹æ¯” ----------
    def generate_inverse_demand_shift_plot(self, filename='å›¾7.X_å€’éœ€æ±‚_Î´å¯¹æ¯”_ä¸»ç²®ä¸»èœ.png'):
        print("\nğŸ“Š ç”Ÿæˆå€’éœ€æ±‚æ›²çº¿ï¼ˆä¸»ç²®/ä¸»èœï¼ŒÎ´å¯¹æ¯”ï¼‰...")
        set_plot_style()

        # å®šä¹‰ç±»åˆ«
        def is_grain(crop_info):
            t = crop_info.get('type', '')
            return ('ç²®é£Ÿ' in t)
        def is_veg(crop_info):
            t = crop_info.get('type', '')
            return ('è”¬èœ' in t)

        # ä»¥å½“å‰æœ€ä¼˜è§£çš„é¢ç§¯ä¸åŸºå‡†äº§é‡æ„é€ Qï¼ˆé¿å…ä¸åŒæƒ…æ™¯å¸¦æ¥çš„ä¾›ç»™æ³¢åŠ¨ï¼‰
        grains = []  # (Q_t, P_t) per year
        vegs = []
        # å½“å‰ï¼ˆå«Î´ï¼‰ä»·æ ¼å‡å€¼
        mean_price = {(j, t): float(np.mean([sc[j][t]['price'] for sc in self.base.scenarios])) for j in self.base.crop_info for t in self.base.years}
        # æ„é€ ä¸å«Î´çš„ä»·æ ¼å‡å€¼ï¼šé‡ç”Ÿæˆä¸€æ¬¡æƒ…æ™¯ï¼ˆç›¸åŒéšæœºç§å­ï¼‰ï¼Œä¸è¿›è¡Œ~å‚æ•°æ›´æ–°
        # å¤‡ä»½
        scenarios_backup = self.base.scenarios
        try:
            # é‡æ–°ç”ŸæˆåŸºç¡€æƒ…æ™¯ä¸Copula
            self.base.generate_stochastic_scenarios()
            self.generate_correlated_scenarios()
            mean_price_no_delta = {(j, t): float(np.mean([sc[j][t]['price'] for sc in self.base.scenarios])) for j in self.base.crop_info for t in self.base.years}
        finally:
            # æ¢å¤åŸåœºæ™¯ï¼ˆå«Î´åçš„ï¼‰
            self.base.scenarios = scenarios_backup

        # èšåˆåˆ°ä¸»ç²®/ä¸»èœï¼ˆæŒ‰å¹´ï¼‰
        all_lands = {**self.base.grain_lands, **self.base.irrigation_lands, **self.base.greenhouse_lands}
        for year in self.base.years:
            Q_grain = 0.0
            P_grain = []
            Q_veg = 0.0
            P_veg = []
            for land_name, year_solution in self.base.optimal_solution.items():
                if year not in year_solution:
                    continue
                for season, season_solution in year_solution[year].items():
                    for crop_id, area in season_solution.items():
                        ci = self.base.crop_info[crop_id]
                        y_base = ci['yield_base']
                        q = area * y_base
                        p_on = mean_price[(crop_id, year)]
                        p_off = mean_price_no_delta[(crop_id, year)]
                        if is_grain(ci):
                            Q_grain += q
                            P_grain.append((p_on, p_off, q))
                        elif is_veg(ci):
                            Q_veg += q
                            P_veg.append((p_on, p_off, q))
            # æŒ‰äº§é‡åŠ æƒçš„å‡ä»·ï¼ˆæ›´è´´è¿‘å¸‚åœºå‡è¡¡å£å¾„ï¼‰
            def weighted_mean(items):
                if not items:
                    return (np.nan, np.nan)
                w = np.array([it[2] for it in items], dtype=float)
                p_on = np.sum(w * np.array([it[0] for it in items])) / np.sum(w)
                p_off = np.sum(w * np.array([it[1] for it in items])) / np.sum(w)
                return float(p_on), float(p_off)
            p_on_g, p_off_g = weighted_mean(P_grain)
            p_on_v, p_off_v = weighted_mean(P_veg)
            if Q_grain > 0 and not np.isnan(p_on_g) and not np.isnan(p_off_g):
                grains.append((Q_grain, p_on_g, p_off_g))
            if Q_veg > 0 and not np.isnan(p_on_v) and not np.isnan(p_off_v):
                vegs.append((Q_veg, p_on_v, p_off_v))

        def fit_and_plot(ax, data, title):
            if len(data) < 2:
                ax.set_title(f"{title}ï¼ˆæ ·æœ¬ä¸è¶³ï¼‰")
                return
            Q = np.array([d[0] for d in data], dtype=float)
            P_on = np.array([d[1] for d in data], dtype=float)
            P_off = np.array([d[2] for d in data], dtype=float)
            coef_on = np.polyfit(Q, P_on, 1)
            coef_off = np.polyfit(Q, P_off, 1)
            qline = np.linspace(Q.min()*0.95, Q.max()*1.05, 100)
            ax.scatter(Q/1e6, P_off, c='gray', s=25, alpha=0.7, label='ä¸å«Î´ï¼ˆç‚¹ï¼‰')
            ax.scatter(Q/1e6, P_on, c='steelblue', s=25, alpha=0.7, label='å«Î´ï¼ˆç‚¹ï¼‰')
            ax.plot(qline/1e6, np.polyval(coef_off, qline), '--', color='gray', label=f"ä¸å«Î´: p={coef_off[0]:.2e}Â·Q+{coef_off[1]:.2f}")
            ax.plot(qline/1e6, np.polyval(coef_on, qline), '-', color='steelblue', label=f"å«Î´: p={coef_on[0]:.2e}Â·Q+{coef_on[1]:.2f}")
            # æ³¨é‡Šï¼šåœ¨å‡å€¼Qå¤„çš„ä»·æ ¼å·®
            qm = Q.mean()
            dm = np.polyval(coef_on, qm) - np.polyval(coef_off, qm)
            ax.annotate(f"Î´è‡´æ›²çº¿ç§»åŠ¨: {dm:.2f}å…ƒ/æ–¤ @Qå‡å€¼", xy=(qm/1e6, np.polyval(coef_on, qm)),
                        xytext=(qm/1e6, np.polyval(coef_on, qm)+0.05*max(1.0, P_on.mean())),
                        arrowprops=dict(arrowstyle='->', color='red'), color='red', fontsize=9)
            ax.set_xlabel('ä¾›ç»™é‡Qï¼ˆç™¾ä¸‡æ–¤ï¼‰')
            ax.set_ylabel('å‡ä»·pï¼ˆå…ƒ/æ–¤ï¼‰')
            ax.set_title(title)
            ax.grid(alpha=0.3)
            ax.legend()

        fig, axes = plt.subplots(1, 2, figsize=(12.5, 5.6))
        fit_and_plot(axes[0], grains, 'ä¸»ç²®ï¼šå€’éœ€æ±‚æ›²çº¿ï¼ˆÎ´å¯¹æ¯”ï¼‰')
        fit_and_plot(axes[1], vegs, 'ä¸»èœï¼šå€’éœ€æ±‚æ›²çº¿ï¼ˆÎ´å¯¹æ¯”ï¼‰')
        plt.tight_layout()
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ç”Ÿæˆï¼š{filename}")

    # ---------- ä½œä¸šæ¸…å•ä¸æ›´æ›¿ç”˜ç‰¹å›¾ã€å¤§æ£šæœˆåº¦åˆ©ç”¨ç‡ ----------
    def export_operation_schedule_and_gantt(self, schedule_csv='é—®é¢˜ä¸‰_ä½œä¸šæ¸…å•.csv', gantt_png='å›¾7.X_ä½œç‰©æ›´æ›¿ç”˜ç‰¹å›¾.png'):
        print("\nğŸ“‹ å¯¼å‡ºä½œä¸šæ¸…å•å¹¶ç”Ÿæˆæ›´æ›¿ç”˜ç‰¹å›¾...")
        all_lands = {**self.base.grain_lands, **self.base.irrigation_lands, **self.base.greenhouse_lands}

        def months_for(land_type: str, season: int):
            if land_type == 'æ°´æµ‡åœ°' or land_type in ['æ™®é€šå¤§æ£š', 'æ™ºæ…§å¤§æ£š']:
                return (3, 6) if season == 1 else (7, 10)
            else:  # ç²®é£Ÿç±»å•å­£
                return (4, 9)

        rows = []
        for land_name, land_solution in self.base.optimal_solution.items():
            ltype = all_lands[land_name]['type']
            for year, year_solution in land_solution.items():
                for season, season_solution in year_solution.items():
                    for crop_id, area in season_solution.items():
                        if area <= 0.01:
                            continue
                        crop_info = self.base.crop_info[crop_id]
                        sow_m, harv_m = months_for(ltype, season)
                        rows.append({
                            'åœ°å—åç§°': land_name,
                            'åœ°å—ç±»å‹': ltype,
                            'å¹´ä»½': year,
                            'å­£èŠ‚': season,
                            'ä½œç‰©ç¼–å·': crop_id,
                            'ä½œç‰©åç§°': crop_info['name'],
                            'ç§æ¤é¢ç§¯(äº©)': round(float(area), 2),
                            'æ’­ç§æœˆ': sow_m,
                            'æ”¶è·æœˆ': harv_m,
                        })
        df = pd.DataFrame(rows)
        df.sort_values(['åœ°å—åç§°', 'å¹´ä»½', 'å­£èŠ‚'], inplace=True)
        df.to_csv(schedule_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… å·²ç”Ÿæˆï¼š{schedule_csv}")

        # ç”Ÿæˆç”˜ç‰¹å›¾ï¼šé€‰å–é¢ç§¯æ€»é‡Top12åœ°å—
        totals = df.groupby('åœ°å—åç§°')['ç§æ¤é¢ç§¯(äº©)'].sum().sort_values(ascending=False)
        top_lands = list(totals.head(12).index)
        gdf = df[df['åœ°å—åç§°'].isin(top_lands)].copy()
        # å°†(å¹´, æœˆ)æ˜ å°„åˆ°æ€»æœˆä»½åºå·ï¼ˆä»2024-01å¼€å§‹ï¼‰
        def month_index(year, m):
            return (year - 2024) * 12 + (m - 1)
        gdf['start'] = [month_index(y, m) for y, m in zip(gdf['å¹´ä»½'], gdf['æ’­ç§æœˆ'])]
        gdf['end'] = [month_index(y, m) for y, m in zip(gdf['å¹´ä»½'], gdf['æ”¶è·æœˆ'])]

        set_plot_style()
        fig, ax = plt.subplots(figsize=(12.8, 6.8))
        # é¢œè‰²æŒ‰ä½œç‰©ç±»åˆ«åŒºåˆ†
        def crop_color(crop_id: int) -> str:
            info = self.base.crop_info.get(crop_id, {})
            t = str(info.get('type', ''))
            if 'è±†' in t:
                return 'tab:green'
            if 'å°éº¦' in info.get('name', '') or 'ç²®' in t:
                return 'tab:orange'
            if 'ç‰ç±³' in info.get('name', ''):
                return 'tab:olive'
            if 'ç“œ' in info.get('name', ''):
                return 'tab:cyan'
            if 'è–¯' in info.get('name', ''):
                return 'tab:brown'
            if 'èŒ' in t:
                return 'tab:purple'
            if 'è”¬' in t:
                return 'tab:blue'
            return 'steelblue'
        yticks = []
        ylabels = []
        y = 0
        for land in top_lands:
            sub = gdf[gdf['åœ°å—åç§°'] == land]
            for _, r in sub.iterrows():
                color = crop_color(int(r['ä½œç‰©ç¼–å·']))
                ax.barh(y, r['end'] - r['start'] + 1, left=r['start'], height=0.72,
                        color=color, alpha=0.75, edgecolor='white', linewidth=0.6)
                ax.text(r['start'] + 0.2, y, f"{int(r['å¹´ä»½'])}å¹´S{int(r['å­£èŠ‚'])}-{r['ä½œç‰©åç§°']} ({r['ç§æ¤é¢ç§¯(äº©)']}äº©)",
                        fontsize=8.5, va='center', color='black')
            yticks.append(y)
            ylabels.append(land)
            y += 1
        ax.set_yticks(yticks)
        ax.set_yticklabels(ylabels)
        ax.set_xlabel('æ—¶é—´ï¼ˆæœˆï¼Œä»2024-01èµ·ï¼‰')
        ax.set_title('é—®é¢˜ä¸‰ ä½œç‰©æ›´æ›¿ç”˜ç‰¹å›¾ï¼ˆTop12åœ°å—ï¼‰')
        # å¹´åº¦åˆ†éš”çº¿
        for yr in range(2024, int(gdf['å¹´ä»½'].max()) + 1):
            ax.axvline((yr - 2024) * 12, color='lightgray', linewidth=0.8)
        ax.grid(alpha=0.35, axis='x')
        plt.tight_layout()
        plt.savefig(gantt_png, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ç”Ÿæˆï¼š{gantt_png}")

    def generate_greenhouse_monthly_utilization(self, out_csv='é—®é¢˜ä¸‰_å¤§æ£šæœˆåº¦åˆ©ç”¨ç‡.csv', out_png='å›¾7.X_å¤§æ£šæœˆåº¦åˆ©ç”¨ç‡.png'):
        print("\nğŸ  ç”Ÿæˆå¤§æ£šæœˆåº¦ååç‡ä¸åˆ©ç”¨ç‡...")
        greenhouses = {**self.base.greenhouse_lands}
        if not greenhouses:
            print("âš ï¸ æ— å¤§æ£šåœ°å—ï¼Œè·³è¿‡")
            return
        total_area = sum(info['area'] for info in greenhouses.values())

        def months_for(land_type: str, season: int):
            return (3, 6) if season == 1 else (7, 10)

        # æœˆåºåˆ—
        months = [(year, m) for year in self.base.years for m in range(1, 13)]
        idx_map = {(y, m): (y - 2024) * 12 + (m - 1) for (y, m) in months}
        occ = np.zeros(len(months), dtype=float)
        thru = np.zeros(len(months), dtype=float)

        # é¢„ä¼°äº§å‡ºæŒ‰å­£å‡æ‘Šåˆ°æœˆä»½
        mean_yield_factor = {(j, t): float(np.mean([sc[j][t]['yield_factor'] for sc in self.base.scenarios])) for j in self.base.crop_info for t in self.base.years}

        for land_name, land_solution in self.base.optimal_solution.items():
            if land_name not in greenhouses:
                continue
            ltype = greenhouses[land_name]['type']
            for year, year_solution in land_solution.items():
                for season, season_solution in year_solution.items():
                    sow_m, harv_m = months_for(ltype, season)
                    dur = max(1, harv_m - sow_m + 1)
                    for crop_id, area in season_solution.items():
                        if area <= 0.01:
                            continue
                        # å ç”¨
                        for m in range(sow_m, harv_m + 1):
                            occ[idx_map[(year, m)]] += float(area)
                        # ååï¼ˆæŒ‰å­£åˆ†æ‘Šï¼‰
                        y_base = self.base.crop_info[crop_id]['yield_base']
                        yf = mean_yield_factor[(crop_id, year)]
                        production = float(area) * y_base * yf
                        per_month = production / dur
                        for m in range(sow_m, harv_m + 1):
                            thru[idx_map[(year, m)]] += per_month

        util = occ / max(1e-6, total_area)
        # å¯¼å‡ºCSV
        rows = []
        for (y, m) in months:
            k = idx_map[(y, m)]
            rows.append({'å¹´ä»½': y, 'æœˆä»½': m, 'å ç”¨é¢ç§¯(äº©)': round(occ[k], 2), 'æ€»å¤§æ£šé¢ç§¯(äº©)': round(total_area, 2), 'åˆ©ç”¨ç‡': round(util[k], 4), 'äº§å‡º(æ–¤)': round(thru[k], 2)})
        pd.DataFrame(rows).to_csv(out_csv, index=False, encoding='utf-8-sig')
        print(f"âœ… å·²ç”Ÿæˆï¼š{out_csv}")

        # ç»˜å›¾
        set_plot_style()
        fig, ax1 = plt.subplots(figsize=(12.8, 4.8))
        x = np.arange(len(months))
        ax1.plot(x, util * 100, '-', color='tab:blue', marker='o', markersize=3, label='åˆ©ç”¨ç‡(%)')
        ax1.set_ylabel('åˆ©ç”¨ç‡(%)')
        ax1.set_xlabel('æ—¶é—´ï¼ˆæœˆï¼Œä»2024-01èµ·ï¼‰')
        ax2 = ax1.twinx()
        ax2.bar(x, thru / 1e6, color='tab:cyan', alpha=0.35, label='åå(ç™¾ä¸‡æ–¤)')
        ax2.set_ylabel('ååï¼ˆç™¾ä¸‡æ–¤ï¼‰')
        ax1.set_title('å¤§æ£šæœˆåº¦åˆ©ç”¨ç‡ä¸ååé‡ï¼ˆé—®é¢˜ä¸‰æ–¹æ¡ˆï¼‰')
        # åˆå¹¶å›¾ä¾‹
        lines1, labels1 = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        # å¹´åº¦åˆ†éš”çº¿
        for yr in range(2024, max(self.base.years) + 1):
            ax1.axvline((yr - 2024) * 12, color='lightgray', linewidth=0.8)
        plt.tight_layout()
        plt.savefig(out_png, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"âœ… å·²ç”Ÿæˆï¼š{out_png}")

    # ---------- å¤šéšæœºç§å­è¯¯å·®å¸¦ï¼ˆK=1000, seeds={42,123,2024}ï¼‰ ----------
    def run_multi_seed_error_band(self, seeds=(42, 123, 2024), out_png='é—®é¢˜ä¸‰_å¤šç§å­è¯¯å·®å¸¦.png', out_csv='é—®é¢˜ä¸‰_å¤šç§å­è¯¯å·®å¸¦.csv', saa: int | None = None):
        print("\nğŸ§ª å¤šéšæœºç§å­è¯¯å·®å¸¦å®éªŒï¼šK=1000, seeds=", seeds)
        if saa is not None:
            self.base.N_saa = int(saa)
        rows = []
        xs = []
        means = []
        stds = []
        for seed in seeds:
            # å…¨æµç¨‹ï¼šé‡ç½®â†’æƒ…æ™¯â†’Copulaâ†’SAAâ†’æ±‚è§£â†’å…¨æƒ…æ™¯éªŒè¯
            self.base.load_and_process_data()
            self.build_relationships()
            # è®¾ç½®éšæœºç§å­
            try:
                self.base.random_seed = int(seed)
            except Exception:
                pass
            self.base.N_scenarios = 1000
            self.base.generate_stochastic_scenarios()
            self.generate_correlated_scenarios()
            self.base.select_representative_scenarios()
            self.base.use_tail_cvar = False
            self.base.build_stochastic_programming_model()
            ok = self.base.solve_model()
            if not ok:
                print(f"   âš ï¸ ç§å­{seed}æ±‚è§£å¤±è´¥ï¼Œè·³è¿‡")
                continue
            metrics = self.validate_with_synergy()
            rows.append({'seed': seed, **metrics})
            xs.append(seed)
            means.append(metrics['expected_profit'])
            stds.append(metrics['profit_std'])
        if rows:
            df = pd.DataFrame(rows)
            df.to_csv(out_csv, index=False, encoding='utf-8-sig')
            print(f"âœ… å·²ç”Ÿæˆï¼š{out_csv}")
            # ç»˜å›¾ï¼šå‡å€¼Â±1Ïƒ
            set_plot_style()
            order = np.argsort(xs)
            xs_plot = np.array(xs)[order]
            means_plot = np.array(means)[order]
            stds_plot = np.array(stds)[order]
            fig, ax = plt.subplots(figsize=(8.0, 5.2))
            ax.plot(xs_plot, means_plot/1e6, '-o', color='tab:blue', label='æœŸæœ›æ”¶ç›Š')
            ax.fill_between(xs_plot, (means_plot-stds_plot)/1e6, (means_plot+stds_plot)/1e6,
                            color='tab:blue', alpha=0.2, label='Â±1Ïƒ åŒºé—´')
            ax.set_xlabel('éšæœºç§å­')
            ax.set_ylabel('æ”¶ç›Šï¼ˆç™¾ä¸‡å…ƒï¼‰')
            ax.set_title('é—®é¢˜ä¸‰ å¤šéšæœºç§å­è¯¯å·®å¸¦ï¼ˆK=1000ï¼‰')
            ax.legend()
            plt.tight_layout()
            plt.savefig(out_png, dpi=300, bbox_inches='tight')
            plt.close()
            print(f"âœ… å·²ç”Ÿæˆï¼š{out_png}")


def main():
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='ignore')
        sys.stderr.reconfigure(encoding='utf-8', errors='ignore')
    except Exception:
        pass

    solver = Problem3CorrelatedSubstitutionSolver()
    metrics = solver.run(iterations=2)
    print("\nå…³é”®æŒ‡æ ‡ï¼š")
    for k, v in metrics.items():
        print(f" - {k}: {v:,.2f}")
    return solver


if __name__ == '__main__':
    main()


